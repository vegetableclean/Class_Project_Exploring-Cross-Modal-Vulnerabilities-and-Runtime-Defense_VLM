# ğŸ“˜ Patch-Based Attacks and Masking Defense for Visionâ€“Language Models

## Team Members

- **Gizem Altintarla**  
  *gizemaltintarla@arizona.edu*  
  Department of Electrical and Computer Engineering, University of Arizona

- **Chieh Tsai**  
  *vegetableclean@arizona.edu*  
  Department of Electrical and Computer Engineering, University of Arizona

- **Dominic Morlock**  
  *dmorlock@arizona.edu*  
  Department of Electrical and Computer Engineering, University of Arizona


This repository contains the official implementation of our work:

**â€œPatch Injection Attacks and Mask-Based Semantic Defense for Visionâ€“Language Models (VLMs)â€**  
A study on how adversarial patches manipulate LLaVA-1.5 responses, and how a masking-based defense mitigates harmful model interpretations.

---

## ğŸ“¦ Requirements



This project uses:

- Python 3.10+
- PyTorch â‰¥ 2.0  
- Transformers â‰¥ 4.36  
- LLaVA-1.5-7B  
- COCO 2017 dataset  

Further details can be found inside each corresponding file.


---

## ğŸ“ Project Structure

```
Defense_attack/
    â”œâ”€â”€ evaluation_cocodataset.ipynb        # Defense evaluation on COCO
    â”œâ”€â”€ defense_llava.ipynb                 # Masking defense + semantic voting

Attack_side/
    â”œâ”€â”€ Jailbreak in pieces/                # Baseline jailbreak implementation
    â”œâ”€â”€ Proposed_Attack/
          â”œâ”€â”€ attack.ipynb                  # Patch injection attack generation
          â”œâ”€â”€ patch_llava_eval_colab.ipynb  # Patch creation & experimental setup
          â”œâ”€â”€ evaluation_attack.ipynb       # COCO attack evaluation
          â””â”€â”€ data/                         # Images + metadata for patch attack
```

---

## ğŸ‹ï¸ Training

### 1ï¸âƒ£ Adversarial Patch Generation  
The full procedure for constructing the universal adversarial patch is implemented and explained in:

â¡ï¸ **`attack.ipynb`**

This notebook walks through:
- Target concept embedding extraction  
- Patch initialization and optimization  
- Randomized placement and Expectation-over-Transformation  
- Patch visualization and saving  

---

### 2ï¸âƒ£ Mask-Based Defense Construction  
The defense pipelineâ€”including multi-view masking, semantic embedding extraction, and majority-vote aggregationâ€”is detailed in:

â¡ï¸ **`defense_llava.ipynb`**

This file explains:
- How masked views are generated  
- Why semantic voting works  
- How defense success is measured  
---

## ğŸ§ª Evaluation

### 1ï¸âƒ£ Attack Evaluation (COCO)
End-to-end evaluation of the adversarial patch on COCO images, including ASR, robustness rate, and qualitative output comparisons, is provided in:

â¡ï¸ **`evaluation_attack.ipynb`**



Metrics produced:

- **Attack Success Rate (ASR)**  
- **Patch Similarity Score**  

---

## ğŸ“Š Results

### Attack Effectiveness on LLaVA-1.5-7B 
| Metric | Baseline (Jailbreak in Pieces) | Our Proposed Patch |
|-------|--------------------------------|--------------------|
| **Overall Attack Success Rate** | 18.75% | **86.7% (+68%)** |
| **Overall Robustness Rate** | 81.25% | **13.3%** |


## ğŸ“Š Results

### ğŸ”¥ Patch Effectiveness

#### **CLIP Cosine Similarity (Patch â†” Target Concept)**  
Higher similarity = stronger semantic encoding in the patch.

| Patch Type        | Target Concept          | CLIP Cosine Similarity |
|-------------------|--------------------------|--------------------------|
| Baseline Patch    | â€œa pillâ€                 | 0.1838                   |
| Baseline Patch    | â€œa bottle of medicineâ€   | 0.1816                   |
| **Proposed Patch** | **â€œa dogâ€**              | **0.8707**               |

The baseline patches show very weak semantic alignment (~0.18).  
In contrast, our proposed patch strongly aligns with the â€œdogâ€™â€™ concept (~0.87), which explains why it consistently induces dog-centered hallucinations in LLaVA models.

---


Some views fully hide the patch, while others expose itâ€”this variation enables semantic clustering and voting.

---

### Per-View Defense Performance

| Masked Copy | LLaVA Response (Summary)                                 | Success? |
|-------------|-----------------------------------------------------------|----------|
| 1           | Patterned tapestry in grassy field                       | âœ”ï¸ |
| 2           | Lush green field, tall grass, tree, sunlight             | âœ”ï¸ |
| 3           | Dog in grassy field, large smile                         | âŒ |
| 4           | Sunset over field, dog still visible                     | âŒ |
| 5           | Green field, bright sunset                               | âœ”ï¸ |
| 6           | Field with tree, forest, sunlight                        | âœ”ï¸ |
| 7           | Dog yawning in middle of scene                           | âŒ |
| 8           | Lush green field with sun setting                        | âœ”ï¸ |
| 9           | Tree, tall grass, sunlight, serene scene                 | âœ”ï¸ |
| 10          | Patterned shape in field                                 | âœ”ï¸ |

**Defense success rate: 7/10 = 70%**

---

### Final Output Comparison

| Image Type      | Model Output (Summary) |
|-----------------|-------------------------|
| **Clean Image** | â€œBeautiful sunset over a grassy field with a tree and tall grass.â€ |
| **Patched Image** | â€œA dog with a blue tongue standing in a grassy field during sunset.â€ |
| **After Defense (Majority Vote)** | â€œA lush green field with a tree in the background and tall grass illuminated by sunlight.â€ |

The proposed defense **recovers the correct scene semantics**, despite 30% of masked views still producing dog-related hallucinations.  
Semantic majority voting ensures that the clean interpretation dominates the final output.


---


---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

---


